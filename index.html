<!DOCTYPE html>

<html lang="en">
	<head>
		<title>Yingshu CHEN (Susan) | 陈颖舒 </title>
		<meta charset="utf-8"/>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta content="chenyingshu Yingshu Chen Susan HKUST" name="keywords">
		<meta content="Susan's Personal Webpage" name="description">
		<link rel="stylesheet" type="text/css" href="./css/style.css">
		<meta name="google-site-verification" content="S5nCw19pRq7mIILllS376ov6_nr0qm_EJrEyhYHOdWM" />
	</head>

	<body>
		<header>
			<div class="avator-counter">
				<img class="avator" src="./images/cys.jpg">
			</div>

			<div class="info-counter">
				<h1>Yingshu CHEN (Susan) <span lang="cn">陈颖舒</span></h1>
				<p><b>E-MAIL</b>：yingshu2008[AT]gmail[DOT]com </p>
				<p><b>LINKEDIN</b>：<a href="https://cn.linkedin.com/in/yingshu-chen-a0550aa7" target="_blank">https://cn.linkedin.com/in/yingshu-chen-a0550aa7</a></p>
				<h5 class="info-text">Yingshu CHEN is currently a PhD candidate in the Department of Computer Science and Engineering, the Hong Kong University of Science and Technology (HKUST) supervised by Sai-Kit Yeung and Ajay Joneja.
					Her research interests cover computer vision and computer graphics for computational design such as 2D and 3D style transfer.
					Yingshu received her B.Eng in Digital Media Technology from Zhejiang University in 2016 and M.Sc in Computer Science from The University of Hong Kong in 2018.</h5>
			</div>
		</header>

		&nbsp;&nbsp;&nbsp;&nbsp;<section class="container">

			<div class="sub-container">
				<h1>EDUCATION AND WORKING EXPERIENCE</h1>
				<div class="sub-text-container">
					<p>August 2019 - Now, PhD student in Department of Computer Science and Engineering, HKUST</p>
					<p>Summer 2019, Research Assistant of Division of Integrative Systems and Design, HKUST</p>
					<p>2018 – 2019, Analytics Programmer,  Aigens Limited Technology (Hong Kong)</p>
					<!-- <p>October 2017, Activity Helper and Cantonese-Putonghua Interpreter, Centre for Educational Leadership (CEL) Gansu Professional Training, Faculty of Education in HKU</p> -->
					<p>2016 – 2018, Master of Science in Computer Science, The University of Hong Kong</p>
					<p>2012 – 2016, Bachelor of Engineering in Digital Media Technology, Zhejiang University</p>
				</div>
			</div>


			<div class="sub-container publication">
				<h1>SELECTED PUBLICATIONS</h1>
				<div class="publication-container sub-text-container">
					<div class="thumbnail-counter">
						<img class="thumbnail" src="images/paper/thumbnail_360roam2022.png">
					</div>
					<div class="paper-info-counter">
						<p><b>360Roam: Real-Time Indoor Roaming Using Geometry-Aware 360ᵒ Radiance Fields</b> </p>
						<p>Huajian Huang, <i><b>Yingshu Chen</b></i>, Tianjian Zhang, Sai-Kit Yeung
							<!--							<br> SIGGRAPH Asia 2022 Technical Communications (to appear).-->
						</p>
						<span>
<!--							<a href="#" target="_blank">[Paper]</a>-->
							<a href="https://huajianup.github.io/research/360Roam/" target="_blank">[Project]</a>
							<a href="https://arxiv.org/abs/2208.02705" target="_blank">[Arxiv]</a>
							<!--							<a href="#" target="_blank">[Data]</a>-->
						</span>
						<p class="abstract"><small><i>360Roam</i> is a novel scene-level NeRF system that can synthesize novel views of large-scale indoor scenes and support real-time indoor roaming.</small></p>
					</div>

				</div>

				<div class="publication-container">

					<div class="thumbnail-counter">
						<img class="thumbnail" src="images/paper/thumbnail_eccv2022.png">
					</div>
					<div class="paper-info-counter">
						<p><b>Neural Scene Decoration from a Single Photograph</b> </p>
						<p>Hong Wing Pang, <i><b>Yingshu Chen</b></i>, Phuoc-Hieu T. Le, Binh-Son Hua, Thanh Nguyen, Sai-Kit Yeung
							<br> European Conference on Computer Vision (ECCV) 2022. </p>
						<span>
							<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136830137.pdf" target="_blank">[Paper]</a>
							<a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136830137-supp.pdf" target="_blank">[Supp]</a>
							<a href="https://arxiv.org/abs/2108.01806" target="_blank">[Arxiv]</a>
							<a href="https://github.com/hkust-vgd/neural_scene_decoration" target="_blank">[Code]</a>
						</span>
						<p class="abstract"> <small>Given a photograph of an empty indoor space and a list of decorations with layout determined by user,
							we aim to synthesize a new image of the same space with desired furnishing and decorations. </small></p>
					</div>
				</div>
				<div class="publication-container sub-text-container">
					<div class="thumbnail-counter">
						<img class="thumbnail" src="images/paper/thumbnail_iccp2022.png">
					</div>
					<div class="paper-info-counter">
						<p><b>Time-of-Day Neural Style Transfer for Architectural Photographs</b> </p>
						<p><i><b>Yingshu Chen</b></i>, Tuan-Anh Vu, Ka-Chun Shum, Binh-Son Hua, Sai-Kit Yeung
							<br> International Conference on Computational Photography (ICCP) 2022. </p>
						<span>
							<a href="https://chenyingshu.github.io/time_of_day/assets/ICCP_2022_paper_updated.pdf" target="_blank">[Paper]</a>
							<a href="https://chenyingshu.github.io/time_of_day/" target="_blank">[Project]</a>
							<a href="https://arxiv.org/abs/2209.05800" target="_blank">[Arxiv]</a>
							<a href="https://github.com/hkust-vgd/architectural_style_transfer" target="_blank">[Code]</a>
							<a href="https://github.com/hkust-vgd/architectural_style_transfer#dataset" target="_blank">[Data]</a>
							<a href="https://ieeexplore.ieee.org/document/9887763/" target="_blank">[IEEE]</a>
						</span>

						<p class="abstract"><small>Architectural Photography Style Transfer aims to transfer background dynamic texture and chrominance,
							and transfer sufficient styles for foreground while keeping foreground geometry intact.</small></p>
					</div>
				</div>

<!--				<h1>PREPRINTS</h1>-->

			</div>


			<div class="sub-container">
				<h1>PROJECTS</h1>
				<div class="sub-text-container">
					<p><a href="./ad-transfer" target="_blank">3D Advertisement Poster</a> (WebGL): A web-based demo for 3D advertisment display. </p>
					<p><a href="https://github.com/chenyingshu/ThinkTypeSystem" target="_blank">Human Computer Interaction via Brainwave Control</a> (C++ and Qt): <a href="https://vimeo.com/243664058" target="_blank">Demo Video</a></p>
					&nbsp;&nbsp;&nbsp;&nbsp;<small>- Study the effect of user interface (UI) elements and human-induced factors on electroencephalography (EEG) signals,
					proposing a brain-computer interface (BCI) typing system through EEG data retrieved from the wireless Emotiv neuroheadset.</small><br>
					<p><a href="https://chenyingshu.github.io/MovieTrendFromDataVisualization/" target="_blank">Movie Trend Visualization</a>: responsible for data collection, overall design, top movie visualization and analysis, webpage design.</p>
					<p><a href="https://vimeo.com/260713934" target="_blank">Design and Method Study of Two-handed Natural Interactive Scene Modeling Applied on Virtual Reality</a> (Unity with C#):</p>
					&nbsp;&nbsp;&nbsp;&nbsp;<small>- Free hand gesture control for simple modeling with Leap Motion.</small><br>
					<p><a href="https://github.com/chenyingshu/Traveling-Website-SRTP" target="_blank">Original Design of Websites with Interaction Visualization</a>: UG Student Research Training Program (SRTP)</p>
				</div>
			</div>

			<div class="sub-container">
				<h1>OTHER REFERENCES</h1>
				<div class="sub-text-container">
	<!--				<--<p><a href="https://yschen.site/my_works">My Works</a></p>-->
					<p><a class="none-decoration" href="./cv_cys.html" target="_blank">Full CV</a></p>
				</div>
			</div>

		</section>

		<footer>
			<hr>
			CONTACT ME :) via YINGSHU2008[AT]GMAIL[DOT]COM
		</footer>

	</body>

</html>
